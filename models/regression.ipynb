{"cells":[{"cell_type":"code","execution_count":20,"id":"IDtz-Nel-7E0","metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1700932464962,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"IDtz-Nel-7E0"},"outputs":[],"source":["use_google_colab = False\n","\n","\n","#set if we want to clean the or load the precleaned data\n","clean_data_again = True\n","# set a debug mode\n","debug = False"]},{"cell_type":"code","execution_count":21,"id":"efIRCfG22AP7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1550,"status":"ok","timestamp":1700932466967,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"efIRCfG22AP7","outputId":"82ec3562-63bf-491e-e225-c4925b2e5eb4"},"outputs":[],"source":["if debug and clean_data_again:\n","  clean_data_again = False\n","  print(\"Warning: debug mode is on and clean_data_again has been reset to False.\")\n","\n","if use_google_colab :\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/ColabNotebooks/sentiMentaL_tweets"]},{"cell_type":"code","execution_count":22,"id":"22e8a0bc","metadata":{"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1700932467967,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"22e8a0bc"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","\n","import sys\n","import os\n","\n","# Get the current working directory\n","current_dir = os.getcwd()\n","\n","# Adjust the path to point to the parent directory\n","parent_dir = os.path.dirname(current_dir)\n","\n","# Add the parent directory to sys.path\n","sys.path.insert(0, parent_dir)\n","\n","\n","import utils_for_regression.vocab_manip as vm\n","import utils_for_regression.hashtag_dealing_methods as hdm\n","import utils_for_regression.pooling as po\n","import utils_for_regression.submission as sub"]},{"cell_type":"code","execution_count":23,"id":"8c857efb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1700932467967,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"8c857efb","outputId":"1f4ecff4-8ce3-49e2-d134-261a022b95e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Word embeddings shape: (101298, 20)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.024581</td>\n","      <td>-0.109968</td>\n","      <td>0.023675</td>\n","      <td>-0.001796</td>\n","      <td>0.093022</td>\n","      <td>-0.010099</td>\n","      <td>-0.025911</td>\n","      <td>-0.012369</td>\n","      <td>0.002293</td>\n","      <td>0.036365</td>\n","      <td>0.031491</td>\n","      <td>-0.009959</td>\n","      <td>-0.043053</td>\n","      <td>-0.032535</td>\n","      <td>0.010818</td>\n","      <td>-0.005218</td>\n","      <td>0.056776</td>\n","      <td>0.025959</td>\n","      <td>-0.095626</td>\n","      <td>0.007661</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         0         1         2         3         4         5         6    \n","0 -0.024581 -0.109968  0.023675 -0.001796  0.093022 -0.010099 -0.025911  \\\n","\n","         7         8         9         10        11        12        13   \n","0 -0.012369  0.002293  0.036365  0.031491 -0.009959 -0.043053 -0.032535  \\\n","\n","         14        15        16        17        18        19  \n","0  0.010818 -0.005218  0.056776  0.025959 -0.095626  0.007661  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["### DATA LOADING\n","# Load the word embeddings\n","word_embeddings = np.load('../word_embeddings/embeddings.npy')\n","df_word_embeddings = pd.DataFrame(word_embeddings)\n","print('Word embeddings shape:', word_embeddings.shape)\n","df_word_embeddings.head(1)\n"]},{"cell_type":"code","execution_count":24,"id":"8955ce2c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1700932467967,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"8955ce2c","outputId":"ef2df9d8-80ff-4920-cb44-e20884096840"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test tweets:                                                    0\n","0  1,sea doo pro sea scooter ( sports with the po...\n"]}],"source":["# Load the test set tweets\n","with open('../twitter-datasets/test_data.txt', 'r', encoding='utf-8') as file:\n","    test_tweets = file.readlines()\n","    df_test_tweets = pd.DataFrame(test_tweets)\n","\n","print('Test tweets:', df_test_tweets.head(1))"]},{"cell_type":"code","execution_count":25,"id":"157abb4e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1700932467968,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"157abb4e","outputId":"447bb399-fc01-4b01-cb9a-c9c113eaf2e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary: ['love', 'go', 'rt', 'get', 'follow', 'like', 'thank', 'know', 'frame', 'one', 'u', 'good', 'lol', 'day', 'want', 'pleas', 'see', 'time', 'back', 'miss']\n"]}],"source":["# Load the vocabulary\n","with open('../word_embeddings/processed_vocab_cut.txt', 'r', encoding='utf-8') as file:\n","    vocabulary = file.read().splitlines()\n","\n","print('Vocabulary:', vocabulary[:20])"]},{"cell_type":"code","execution_count":26,"id":"10cf41ef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1405,"status":"ok","timestamp":1700932469369,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"10cf41ef","outputId":"354d4d5f-15e6-4dca-f876-a145f5ed8b25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Word to embedding shape: (20, 2300)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>love</th>\n","      <th>go</th>\n","      <th>rt</th>\n","      <th>get</th>\n","      <th>follow</th>\n","      <th>like</th>\n","      <th>thank</th>\n","      <th>know</th>\n","      <th>frame</th>\n","      <th>one</th>\n","      <th>...</th>\n","      <th>ocean</th>\n","      <th>chemistri</th>\n","      <th>highli</th>\n","      <th>address</th>\n","      <th>feat</th>\n","      <th>makeup</th>\n","      <th>desk</th>\n","      <th>condit</th>\n","      <th>chillin</th>\n","      <th>bunni</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.024581</td>\n","      <td>-0.017011</td>\n","      <td>-0.029339</td>\n","      <td>-0.004716</td>\n","      <td>-0.021129</td>\n","      <td>-0.020288</td>\n","      <td>-0.034306</td>\n","      <td>-0.071769</td>\n","      <td>0.007265</td>\n","      <td>-0.009445</td>\n","      <td>...</td>\n","      <td>1.21847</td>\n","      <td>-0.284532</td>\n","      <td>0.095295</td>\n","      <td>-0.551883</td>\n","      <td>0.908118</td>\n","      <td>-0.743857</td>\n","      <td>-0.780625</td>\n","      <td>-0.654532</td>\n","      <td>0.6805</td>\n","      <td>-1.136711</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 2300 columns</p>\n","</div>"],"text/plain":["       love        go        rt       get    follow      like     thank   \n","0 -0.024581 -0.017011 -0.029339 -0.004716 -0.021129 -0.020288 -0.034306  \\\n","\n","       know     frame       one  ...    ocean  chemistri    highli   address   \n","0 -0.071769  0.007265 -0.009445  ...  1.21847  -0.284532  0.095295 -0.551883  \\\n","\n","       feat    makeup      desk    condit  chillin     bunni  \n","0  0.908118 -0.743857 -0.780625 -0.654532   0.6805 -1.136711  \n","\n","[1 rows x 2300 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# Create a dictionary to map words to their corresponding embeddings\n","word_to_embedding = {word: word_embeddings[i] for i, word in enumerate(vocabulary)}\n","df_word_embeddings = pd.DataFrame(word_to_embedding)\n","print('Word to embedding shape:', df_word_embeddings.shape)\n","df_word_embeddings.head(1)\n","\n"]},{"cell_type":"code","execution_count":27,"id":"7ecb2448","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1700932469862,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"7ecb2448","outputId":"4a025ad9-997d-4926-ecea-78582b7488c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive tweets shape: (1250000, 1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0\n","0  <user> i dunno justin read my mention or not ...."]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Load positive training tweets and assign labels\n","with open('../twitter-datasets/train_pos_full.txt', 'r', encoding='utf-8') as file:\n","    pos_tweets = file.readlines()\n","\n","pos_labels = np.ones(len(pos_tweets), dtype=int)  # Assign label 1 for positive tweets\n","df_pos_tweets = pd.DataFrame(pos_tweets)\n","\n","print('Positive tweets shape:', df_pos_tweets.shape)\n","\n","df_pos_tweets.head(1)"]},{"cell_type":"code","execution_count":28,"id":"c7de2422","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1700932470175,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"c7de2422","outputId":"4c074839-57cd-46a4-f332-ad3cec1dd1e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Negative tweets shape: (1250000, 1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vinco tresorpack 6 ( difficulty 10 of 10 objec...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0\n","0  vinco tresorpack 6 ( difficulty 10 of 10 objec..."]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Load negative training tweets and assign labels\n","with open('../twitter-datasets/train_neg_full.txt', 'r', encoding='utf-8') as file:\n","    neg_tweets = file.readlines()\n","\n","neg_labels = -1 * np.ones(len(neg_tweets), dtype=int)  # Assign label -1 for negative tweets\n","df_neg_tweets = pd.DataFrame(neg_tweets)\n","\n","print('Negative tweets shape:', df_neg_tweets.shape)\n","df_neg_tweets.head(1)"]},{"cell_type":"code","execution_count":29,"id":"c15efa54","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1700932470537,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"c15efa54","outputId":"c9eac20d-3052-4922-d59b-ce00968af488"},"outputs":[{"name":"stdout","output_type":"stream","text":["positive tweets shape: (1250000, 1)\n","negative tweets shape: (1250000, 1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0\n","0  <user> i dunno justin read my mention or not ...."]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Combine positive and negative tweets and labels\n","df_pos_tweets = pd.DataFrame(pos_tweets)\n","df_neg_tweets = pd.DataFrame(neg_tweets)\n","\n","print(\"positive tweets shape:\", df_pos_tweets.shape)\n","print(\"negative tweets shape:\", df_neg_tweets.shape)\n","df_pos_tweets.head(1)"]},{"cell_type":"markdown","id":"b9050c43","metadata":{},"source":["#### End of the loading"]},{"cell_type":"markdown","id":"08157977","metadata":{"id":"08157977"},"source":["___________________________"]},{"cell_type":"code","execution_count":30,"id":"e56499c3","metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1700932584534,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"e56499c3"},"outputs":[],"source":["if debug:\n","    pos_tweets = pos_tweets[:10]\n","    neg_tweets = neg_tweets[:10]\n","    test_tweets = test_tweets[:10]\n","    #all_tweets = np.concatenate((train_tweets, test_tweets), axis=0)\n","    pos_labels = pos_labels[:10]\n","    neg_labels = neg_labels[:10]\n","    vocabulary = vocabulary[:100]"]},{"cell_type":"code","execution_count":31,"id":"52358435","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All tweets size: 2510000\n","All labels size: 2500000\n"]}],"source":["# Should be 2 times more tweets than labels\n","print('All tweets size:', len(pos_tweets)+ len(neg_tweets)+ len(test_tweets))\n","print('All labels size:', len(pos_labels)+ len(neg_labels))"]},{"cell_type":"code","execution_count":32,"id":"MhFIFQUVMjAf","metadata":{"executionInfo":{"elapsed":11114,"status":"ok","timestamp":1700932493637,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"MhFIFQUVMjAf"},"outputs":[],"source":["#reorder the vocabulary and the word embeddings according to the largest number of occurences first\n","vocabulary, word_embeddings = vm.reorder_vocabulary(pos_tweets, neg_tweets, test_tweets, vocabulary, word_embeddings, clean_data_again, save_counts=True)"]},{"cell_type":"code","execution_count":33,"id":"9jYl0BCSQYAA","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":1044743,"status":"error","timestamp":1700933654425,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"9jYl0BCSQYAA","outputId":"b099e028-b334-4146-cf84-1c0688b62731"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\gross\\Desktop\\sentiMentaL_tweets\\methods\\regression.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gross/Desktop/sentiMentaL_tweets/methods/regression.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# remove hashtags that are not in the vocabulary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gross/Desktop/sentiMentaL_tweets/methods/regression.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pos_tweets, neg_tweets, test_tweets \u001b[39m=\u001b[39m hdm\u001b[39m.\u001b[39;49mprocess_tweets_hashtags(pos_tweets, neg_tweets, test_tweets, vocabulary, clean_data_again)\n","File \u001b[1;32mc:\\Users\\gross\\Desktop\\sentiMentaL_tweets\\utils_for_regression\\hashtag_dealing_methods.py:76\u001b[0m, in \u001b[0;36mprocess_tweets_hashtags\u001b[1;34m(train_tweets_pos, train_tweets_neg, test_tweets, vocabulary, clean_data_again)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m clean_data_again:\n\u001b[0;32m     75\u001b[0m     processed_train_tweets_pos \u001b[39m=\u001b[39m process_tweets_hashtags_parallel(train_tweets_pos, vocabulary)\n\u001b[1;32m---> 76\u001b[0m     processed_train_tweets_neg \u001b[39m=\u001b[39m process_tweets_hashtags_parallel(train_tweets_neg, vocabulary)\n\u001b[0;32m     77\u001b[0m     processed_test_tweets \u001b[39m=\u001b[39m process_tweets_hashtags_parallel(test_tweets, vocabulary)\n\u001b[0;32m     79\u001b[0m     \u001b[39m# Write the contents into files\u001b[39;00m\n\u001b[0;32m     80\u001b[0m            \u001b[39m# Write the contents into a new file\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\gross\\Desktop\\sentiMentaL_tweets\\utils_for_regression\\hashtag_dealing_methods.py:69\u001b[0m, in \u001b[0;36mprocess_tweets_hashtags_parallel\u001b[1;34m(tweets, vocabulary)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_tweets_hashtags_parallel\u001b[39m(tweets, vocabulary):\n\u001b[0;32m     68\u001b[0m     \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mPool(processes\u001b[39m=\u001b[39mmultiprocessing\u001b[39m.\u001b[39mcpu_count()) \u001b[39mas\u001b[39;00m pool:\n\u001b[1;32m---> 69\u001b[0m         processed_tweets \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mstarmap(process_tweet, [(tweet, vocabulary) \u001b[39mfor\u001b[39;49;00m tweet \u001b[39min\u001b[39;49;00m tweets])\n\u001b[0;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m processed_tweets\n","File \u001b[1;32mc:\\Users\\gross\\anaconda3\\envs\\machine_learning\\lib\\multiprocessing\\pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    367\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n","File \u001b[1;32mc:\\Users\\gross\\anaconda3\\envs\\machine_learning\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\gross\\anaconda3\\envs\\machine_learning\\lib\\multiprocessing\\pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n","File \u001b[1;32mc:\\Users\\gross\\anaconda3\\envs\\machine_learning\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n","File \u001b[1;32mc:\\Users\\gross\\anaconda3\\envs\\machine_learning\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# remove hashtags that are not in the vocabulary\n","pos_tweets, neg_tweets, test_tweets = hdm.process_tweets_hashtags(pos_tweets, neg_tweets, test_tweets, vocabulary, clean_data_again)"]},{"cell_type":"code","execution_count":null,"id":"90bc1acc","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1700932132486,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"90bc1acc"},"outputs":[],"source":["#save the words that are not in the vocabulary\n","vm.out_of_vocab_file(pos_tweets, neg_tweets, test_tweets, vocabulary, clean_data_again)"]},{"cell_type":"code","execution_count":null,"id":"61e932bc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab shape: 100\n"]}],"source":["print(\"Vocab shape:\", len(vocabulary))"]},{"cell_type":"code","execution_count":null,"id":"35a2a9f9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":309039,"status":"error","timestamp":1700932442215,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"35a2a9f9","outputId":"651554fb-26e7-474b-be5c-b2dbca5668a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.5\n"]}],"source":["### TRAINING THE LINEAR CLASSIFIER\n","\n","pooling_method = \"weigth\" # \"mean\", \"max\", \"tfidf\", \"weigth\"\n","\n","train_features, test_features = po.get_features(pooling_method, pos_tweets, neg_tweets, test_tweets, word_to_embedding, vocabulary, clean_data_again)\n","# Split the data into training and validation sets\n","labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","\n","train_features = np.array(train_features)\n","labels = np.array(labels)\n","# Assuming train_features and labels are NumPy arrays\n","assert len(train_features) == len(labels), \"Features and labels must be of the same length\"\n","\n","# Generate a permutation of indices\n","shuffled_indices = np.random.permutation(len(train_features))\n","\n","# Apply the shuffled indices to both features and labels\n","shuffled_features = train_features[shuffled_indices]\n","shuffled_labels = labels[shuffled_indices]\n","\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(train_features, labels, test_size=0.1, random_state=42)\n","\n","# Initialize and train the model\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Validate\n","y_pred = model.predict(X_val)\n","accuracy = accuracy_score(y_val, y_pred)\n","print(f\"Validation Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"id":"a300c43e","metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700932442216,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"a300c43e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test features: 10\n"]}],"source":["print('Test features:', len(test_features))"]},{"cell_type":"code","execution_count":null,"id":"0fe11ed8","metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1700932442216,"user":{"displayName":"Monsieur Cacao","userId":"17438377351391691459"},"user_tz":-60},"id":"0fe11ed8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 1  1  1 -1  1  1  1  1 -1  1]\n"]}],"source":["### LINEAR CLASSIFIER PREDICTIONS\n","\n","# Construct feature representations for test tweets\n","\n","# Make predictions\n","y_test_pred = model.predict(test_features)\n","\n","test_data_path = \"../twitter-datasets/test_data.txt\"\n","ids_test = sub.get_test_ids(test_data_path)\n","print(y_test_pred)\n","y_pred = []\n","y_pred = y_test_pred\n","y_pred[y_pred <= 0] = -1\n","y_pred[y_pred > 0] = 1\n","sub.create_csv_submission(ids_test, y_pred, \"../submissions/submission_\"+pooling_method+\"_pooling_and_regression.csv\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":5}
